{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95e90d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gym\n",
      "  Downloading gym-0.26.2.tar.gz (721 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Collecting cloudpickle>=1.2.0\n",
      "  Downloading cloudpickle-2.2.0-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in c:\\users\\prate\\anaconda3\\envs\\ml\\lib\\site-packages (from gym) (4.8.1)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\prate\\anaconda3\\envs\\ml\\lib\\site-packages (from gym) (1.21.2)\n",
      "Collecting gym-notices>=0.0.4\n",
      "  Downloading gym_notices-0.0.8-py3-none-any.whl (3.0 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\prate\\anaconda3\\envs\\ml\\lib\\site-packages (from importlib-metadata>=4.8.0->gym) (3.5.0)\n",
      "Building wheels for collected packages: gym\n",
      "  Building wheel for gym (PEP 517): started\n",
      "  Building wheel for gym (PEP 517): finished with status 'done'\n",
      "  Created wheel for gym: filename=gym-0.26.2-py3-none-any.whl size=827647 sha256=fe032a278fdf07498145526b0e2cc1f5b5d6f4b531d21426403b33730ac7b4d8\n",
      "  Stored in directory: c:\\users\\prate\\appdata\\local\\pip\\cache\\wheels\\af\\2b\\30\\5e78b8b9599f2a2286a582b8da80594f654bf0e18d825a4405\n",
      "Successfully built gym\n",
      "Installing collected packages: gym-notices, cloudpickle, gym\n",
      "Successfully installed cloudpickle-2.2.0 gym-0.26.2 gym-notices-0.0.8\n",
      "Requirement already satisfied: matplotlib in c:\\users\\prate\\anaconda3\\envs\\ml\\lib\\site-packages (3.4.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\prate\\anaconda3\\envs\\ml\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.16 in c:\\users\\prate\\anaconda3\\envs\\ml\\lib\\site-packages (from matplotlib) (1.21.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\prate\\anaconda3\\envs\\ml\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\prate\\anaconda3\\envs\\ml\\lib\\site-packages (from matplotlib) (8.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\prate\\anaconda3\\envs\\ml\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\prate\\anaconda3\\envs\\ml\\lib\\site-packages (from matplotlib) (3.0.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\prate\\anaconda3\\envs\\ml\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install gym\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "76440081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+http://github.com/pyglet/pyglet@pyglet-1.5-maintenance"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone -q http://github.com/pyglet/pyglet 'C:\\Users\\prate\\AppData\\Local\\Temp\\pip-req-build-xihicphs'\n",
      "  Running command git checkout -b pyglet-1.5-maintenance --track origin/pyglet-1.5-maintenance\n",
      "  Branch 'pyglet-1.5-maintenance' set up to track remote branch 'pyglet-1.5-maintenance' from 'origin'.\n",
      "  Switched to a new branch 'pyglet-1.5-maintenance'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Cloning http://github.com/pyglet/pyglet (to revision pyglet-1.5-maintenance) to c:\\users\\prate\\appdata\\local\\temp\\pip-req-build-xihicphs\n",
      "  Resolved http://github.com/pyglet/pyglet to commit 8511e20d25d9e89b8b1d0288b3e0bcc4e98eaa52\n",
      "Building wheels for collected packages: pyglet\n",
      "  Building wheel for pyglet (setup.py): started\n",
      "  Building wheel for pyglet (setup.py): finished with status 'done'\n",
      "  Created wheel for pyglet: filename=pyglet-1.5.27-py3-none-any.whl size=1142329 sha256=be4e821229b8b2b0bfba75c4f714a6c9ca9809e859323f66017b33cc77e1282f\n",
      "  Stored in directory: C:\\Users\\prate\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-k3trakxp\\wheels\\d0\\e4\\4a\\56a07877c50795738e63b0ee84780abc388adc17e945c6900e\n",
      "Successfully built pyglet\n",
      "Installing collected packages: pyglet\n",
      "Successfully installed pyglet-1.5.27\n"
     ]
    }
   ],
   "source": [
    "# !pip install stable-baselines3[extra]\n",
    "# !pip install pyglet==1.5.27\n",
    "!pip install --user --upgrade git+http://github.com/pyglet/pyglet@pyglet-1.5-maintenance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48745000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gym\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3736f07",
   "metadata": {},
   "source": [
    "## Make envirnment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "204ae9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = 'CartPole-v0'\n",
    "env = gym.make(env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d1d1f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04134472,  0.01986947, -0.02149197, -0.02443712], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4aae42c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episocde 1: Score 36.0\n",
      "Episocde 2: Score 19.0\n",
      "Episocde 3: Score 20.0\n",
      "Episocde 4: Score 37.0\n",
      "Episocde 5: Score 14.0\n",
      "Episocde 6: Score 27.0\n",
      "Episocde 7: Score 11.0\n",
      "Episocde 8: Score 32.0\n",
      "Episocde 9: Score 22.0\n",
      "Episocde 10: Score 25.0\n",
      "Episocde 11: Score 33.0\n",
      "Episocde 12: Score 11.0\n",
      "Episocde 13: Score 15.0\n",
      "Episocde 14: Score 14.0\n",
      "Episocde 15: Score 35.0\n",
      "Episocde 16: Score 13.0\n",
      "Episocde 17: Score 27.0\n",
      "Episocde 18: Score 37.0\n",
      "Episocde 19: Score 18.0\n",
      "Episocde 20: Score 32.0\n",
      "Episocde 21: Score 24.0\n",
      "Episocde 22: Score 27.0\n",
      "Episocde 23: Score 63.0\n",
      "Episocde 24: Score 12.0\n",
      "Episocde 25: Score 33.0\n",
      "Episocde 26: Score 16.0\n",
      "Episocde 27: Score 20.0\n",
      "Episocde 28: Score 33.0\n",
      "Episocde 29: Score 26.0\n",
      "Episocde 30: Score 14.0\n",
      "Episocde 31: Score 19.0\n",
      "Episocde 32: Score 20.0\n",
      "Episocde 33: Score 16.0\n",
      "Episocde 34: Score 19.0\n",
      "Episocde 35: Score 25.0\n",
      "Episocde 36: Score 13.0\n",
      "Episocde 37: Score 23.0\n",
      "Episocde 38: Score 11.0\n",
      "Episocde 39: Score 18.0\n",
      "Episocde 40: Score 13.0\n",
      "Episocde 41: Score 21.0\n",
      "Episocde 42: Score 34.0\n",
      "Episocde 43: Score 30.0\n",
      "Episocde 44: Score 26.0\n",
      "Episocde 45: Score 20.0\n",
      "Episocde 46: Score 19.0\n",
      "Episocde 47: Score 24.0\n",
      "Episocde 48: Score 13.0\n",
      "Episocde 49: Score 10.0\n",
      "Episocde 50: Score 17.0\n"
     ]
    }
   ],
   "source": [
    "# In this code we use random steps\n",
    "# This code is to check the working\n",
    "# Model predictions are not being used\n",
    "episodes = 50\n",
    "for epi in range(1,episodes+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    while not done:\n",
    "        env.render()\n",
    "        # This step is not a prediction\n",
    "        # It is a random step\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        score+=reward\n",
    "    print('Episocde {}: Score {}'.format(epi,score))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1a1cf7",
   "metadata": {},
   "source": [
    "## Abou the envirnment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70167551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e5cced9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5947bd20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c1699ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.7495375e+00,  1.7928539e+38, -2.8787401e-01,  2.7560756e+38],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42c58d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RLdata\\\\Logs'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_path = os.path.join('RLdata','Logs')\n",
    "log_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5760d0a5",
   "metadata": {},
   "source": [
    "### Training a PPO model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b057152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(env_name)\n",
    "env = DummyVecEnv([lambda:env])\n",
    "model = PPO('MlpPolicy',env,verbose=1,tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb94b69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to RLdata\\Logs\\PPO_1\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 243  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 8    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 402          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076748948 |\n",
      "|    clip_fraction        | 0.099        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.686       |\n",
      "|    explained_variance   | -0.00366     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.38         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0153      |\n",
      "|    value_loss           | 56.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 516         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009728592 |\n",
      "|    clip_fraction        | 0.0674      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.666      |\n",
      "|    explained_variance   | 0.112       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    value_loss           | 35.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 602         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007273574 |\n",
      "|    clip_fraction        | 0.0779      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.637      |\n",
      "|    explained_variance   | 0.234       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 22.2        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    value_loss           | 55.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 667         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009833993 |\n",
      "|    clip_fraction        | 0.0667      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.611      |\n",
      "|    explained_variance   | 0.24        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 24.9        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    value_loss           | 65.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 718          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076020635 |\n",
      "|    clip_fraction        | 0.0563       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.581       |\n",
      "|    explained_variance   | 0.394        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 20.1         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.014       |\n",
      "|    value_loss           | 58.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 759          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 18           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077181025 |\n",
      "|    clip_fraction        | 0.103        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.591       |\n",
      "|    explained_variance   | 0.69         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 13.8         |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.0151      |\n",
      "|    value_loss           | 36.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 795          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 20           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065038437 |\n",
      "|    clip_fraction        | 0.0695       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.593       |\n",
      "|    explained_variance   | 0.521        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 22.1         |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.0128      |\n",
      "|    value_loss           | 49.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 825          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 22           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043847654 |\n",
      "|    clip_fraction        | 0.0476       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.585       |\n",
      "|    explained_variance   | 0.892        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.87         |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.0064      |\n",
      "|    value_loss           | 20.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 849         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 24          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006471981 |\n",
      "|    clip_fraction        | 0.0477      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.561      |\n",
      "|    explained_variance   | 0.0088      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 29.5        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.006      |\n",
      "|    value_loss           | 64.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x177c837e8e0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a228fc",
   "metadata": {},
   "source": [
    "### Sab=ve and reload a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d620678",
   "metadata": {},
   "outputs": [],
   "source": [
    "PPO_Path = os.path.join('RLdata','SavedModels','PPO_carpole')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "457928b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(PPO_Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "220f24a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "137742d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(PPO_Path,env=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7176a251",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "79fb3f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prate\\anaconda3\\envs\\ML\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:65: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(200.0, 0.0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(model,env,n_eval_episodes=10,render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "006905b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8281db25",
   "metadata": {},
   "source": [
    "## Using Model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb46f14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episocde 1: Score [200.]\n",
      "Episocde 2: Score [200.]\n",
      "Episocde 3: Score [200.]\n",
      "Episocde 4: Score [157.]\n",
      "Episocde 5: Score [200.]\n",
      "Episocde 6: Score [200.]\n",
      "Episocde 7: Score [200.]\n",
      "Episocde 8: Score [200.]\n",
      "Episocde 9: Score [200.]\n",
      "Episocde 10: Score [200.]\n",
      "Episocde 11: Score [200.]\n",
      "Episocde 12: Score [200.]\n",
      "Episocde 13: Score [200.]\n",
      "Episocde 14: Score [200.]\n",
      "Episocde 15: Score [200.]\n",
      "Episocde 16: Score [200.]\n",
      "Episocde 17: Score [200.]\n",
      "Episocde 18: Score [200.]\n",
      "Episocde 19: Score [200.]\n",
      "Episocde 20: Score [200.]\n",
      "Episocde 21: Score [200.]\n",
      "Episocde 22: Score [200.]\n",
      "Episocde 23: Score [200.]\n",
      "Episocde 24: Score [200.]\n",
      "Episocde 25: Score [200.]\n",
      "Episocde 26: Score [200.]\n",
      "Episocde 27: Score [200.]\n",
      "Episocde 28: Score [200.]\n",
      "Episocde 29: Score [200.]\n",
      "Episocde 30: Score [200.]\n",
      "Episocde 31: Score [200.]\n",
      "Episocde 32: Score [200.]\n",
      "Episocde 33: Score [200.]\n",
      "Episocde 34: Score [200.]\n",
      "Episocde 35: Score [200.]\n",
      "Episocde 36: Score [200.]\n",
      "Episocde 37: Score [200.]\n",
      "Episocde 38: Score [200.]\n",
      "Episocde 39: Score [200.]\n",
      "Episocde 40: Score [194.]\n",
      "Episocde 41: Score [200.]\n",
      "Episocde 42: Score [200.]\n",
      "Episocde 43: Score [200.]\n",
      "Episocde 44: Score [200.]\n",
      "Episocde 45: Score [200.]\n",
      "Episocde 46: Score [200.]\n",
      "Episocde 47: Score [200.]\n",
      "Episocde 48: Score [200.]\n",
      "Episocde 49: Score [200.]\n",
      "Episocde 50: Score [200.]\n"
     ]
    }
   ],
   "source": [
    "# In this code we use Predictions\n",
    "# The predictions are made on observations\n",
    "# Model predictions are being used\n",
    "episodes = 50\n",
    "for epi in range(1,episodes+1):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    while not done:\n",
    "        env.render()\n",
    "        # This step is a prediction\n",
    "        # we add the _ to unpack the value\n",
    "        # we do not need the second (states) part\n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        score+=reward\n",
    "    print('Episocde {}: Score {}'.format(epi,score))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9cb3ed",
   "metadata": {},
   "source": [
    "## Use tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "50530694",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_log_path = os.path.join(PPO_Path,'PPO_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4f01ceb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tensorboard --logdir={train_log_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae60e0a2",
   "metadata": {},
   "source": [
    "## Adding a callback to Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcf0727",
   "metadata": {},
   "source": [
    "This is important for training large models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ML]",
   "language": "python",
   "name": "conda-env-ML-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
